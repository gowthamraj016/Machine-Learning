import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

# Generate synthetic data
np.random.seed(42)
X = np.random.rand(100, 2) * 10  # Features (100 points in 2D space)
y = np.random.choice([0, 1], size=100)  # Binary classification labels

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Generate a test grid for visualization
x_test = np.arange(0, 10, 0.1)
y_test = np.arange(0, 10, 0.1)
X_test_grid, Y_test_grid = np.meshgrid(x_test, y_test)
test_points = np.column_stack((X_test_grid.ravel(), Y_test_grid.ravel()))

# kNN Classification for different values of k
for k in [1, 3, 5, 10, 15]:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred_test = knn.predict(test_points)

    plt.figure(figsize=(8, 6))
    plt.scatter(test_points[:, 0], test_points[:, 1], c=y_pred_test, cmap='bwr', alpha=0.3, marker='s')
    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='bwr', edgecolors='k', marker='o')
    plt.xlabel("Feature X")
    plt.ylabel("Feature Y")
    plt.title(f"kNN Classification (k={k})")
    plt.show()
